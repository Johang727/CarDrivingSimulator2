import sys
import os
import json
import shutil
import re
import hashlib
from zipfile import ZipFile
from pathlib import Path
from datetime import datetime

# This script was not made by Johang727, it was generated by AI.


# --- Configuration ---
# NOTE: The project name is used for the input/output .sb3 and the decompiled folder.
PROJECT_NAME: str = "CarDrivingSimulator2" 
DECOMPILED_DIR_NAME: str = f"{PROJECT_NAME}_Decompiled"
BACKUP_DIR_NAME: str = "Backups"

def handle_error(message:str) -> None:
    """Prints an error and exits the script."""
    print(f"\n[ERROR] {message}")
    sys.exit(1)

def create_backup(output_file: Path) -> None:
    """Creates a timestamped backup of the current .sb3 file."""
    backups_folder = Path(BACKUP_DIR_NAME)
    backups_folder.mkdir(exist_ok=True) 
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    backup_file = backups_folder / f"{PROJECT_NAME}_Backup_{timestamp}.sb3"
    
    if output_file.exists():
        shutil.copy(output_file, backup_file)
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Backup created: {backup_file.name}")
    else:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Warning: Cannot create backup, source file does not exist.")

def sanitize_path_name(name: str) -> str:
    """Removes or replaces characters that are illegal in Windows/Linux filenames."""
    # Replace common illegal characters for filenames (<, >, :, ", /, \, |, ?, *) with underscore
    illegal_chars = r'[<>:"/\\|?*]'
    sanitized_name = re.sub(illegal_chars, '_', name)
    
    # Also ensure it's not empty after sanitization
    return sanitized_name.strip() or "Unnamed_Target"

def calculate_md5(filepath: Path) -> str:
    """Calculates the MD5 hash of a file's content."""
    hash_md5 = hashlib.md5()
    with open(filepath, "rb") as f:
        # Read file in chunks to handle large assets
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()

def decompile() -> None:
    """
    Unzips the .sb3, parses project.json, and restructures files 
    into sprite-specific directories for readability and version control.
    """
    sb3_file = Path(f"{PROJECT_NAME}.sb3")
    output_dir = Path(DECOMPILED_DIR_NAME)
    temp_dir = Path("_temp_flat_assets")
    
    print(f"\n--- Decompiling {sb3_file.name} ---")

    # 1. Validation and Cleanup
    if not sb3_file.is_file():
        handle_error(f"Input file \"{sb3_file.name}\" does not exist.")
        
    if output_dir.exists():
        if input(f"Output directory '{output_dir.name}' exists. Overwrite? (y/N): ").lower() != 'y':
            print("Operation canceled.")
            return

    # Prepare directories
    if output_dir.exists():
        shutil.rmtree(output_dir)
    output_dir.mkdir(exist_ok=True)
    
    if temp_dir.exists():
        shutil.rmtree(temp_dir)
    temp_dir.mkdir(exist_ok=True)
    
    # 2. Extract contents to a temporary flat directory
    try:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Unzipping to temporary folder...")
        with ZipFile(sb3_file, 'r') as zip_file:
            zip_file.extractall(temp_dir)
    except Exception as e:
        shutil.rmtree(temp_dir)
        handle_error(f"Failed to unzip {sb3_file.name}. Error: {e}")
        
    project_json_path = temp_dir / "project.json"
    if not project_json_path.is_file():
        handle_error(f"Could not find project.json in the zip file.")
        
    # 3. Load and parse project.json
    try:
        with open(project_json_path, 'r', encoding='utf-8') as f:
            project_data = json.load(f)
    except json.JSONDecodeError:
        handle_error("project.json is corrupted or invalid JSON.")

    # 4. Process Targets (Sprites and Stage)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Parsing project and restructuring files...")
    
    targets = project_data.pop('targets', [])
    
    for target in targets:
        # Sanitize name to handle illegal characters (like '?')
        target_name = sanitize_path_name(target.get('name', 'UNKNOWN_TARGET')) 
        target_dir = output_dir / target_name
        target_dir.mkdir(exist_ok=True)
        assets_dir = target_dir / "Assets"
        assets_dir.mkdir(exist_ok=True)
        
        # Move Assets (Costumes and Sounds) - MUST run before writing the script JSON
        for asset_type in ['costumes', 'sounds']:
            for asset in target.get(asset_type, []):
                md5ext = asset.get('md5ext')
                asset_name = asset.get('name', 'unnamed')
                asset_ext = asset.get('ext') # can be None
                
                if md5ext:
                    source_path = temp_dir / md5ext
                    
                    # --- Asset Copying Logic ---
                    
                    # 1. Attempt to use human-readable name for copying
                    if asset_ext is not None and asset_name and asset_ext.startswith('.'):
                        new_filename = f"{asset_name}{asset_ext}"
                        dest_path = assets_dir / new_filename
                        
                        if source_path.is_file():
                            shutil.copy(source_path, dest_path)
                            
                            # Update JSON to reference the new human-readable name
                            asset['md5ext_placeholder'] = asset['md5ext']
                            asset['md5ext'] = new_filename 
                        else:
                            print(f"[{target_name}] Warning (Decompile): Asset file {md5ext} not found in zip.")
                            
                    # 2. Fallback: If name/ext is missing/invalid, copy using the MD5 hash name.
                    else:
                        dest_path = assets_dir / md5ext # Copy using the hash name
                        
                        if source_path.is_file():
                            shutil.copy(source_path, dest_path)
                            # Do NOT update asset['md5ext'] in the JSON, it remains the hash.
                        else:
                            print(f"[{target_name}] Warning (Decompile): Asset file {md5ext} not found in zip.")


        # Move scripts and properties (The JSON block for this target)
        script_file_path = target_dir / "scripts_and_properties.json"
        with open(script_file_path, 'w', encoding='utf-8') as f:
            json.dump(target, f, indent=4)


    # 5. Save Global Project Metadata (remaining properties of project_data)
    global_metadata_path = output_dir / "global_project_metadata.json"
    with open(global_metadata_path, 'w', encoding='utf-8') as f:
        # Re-add targets as empty array for structure consistency, if needed
        project_data['targets'] = [] 
        json.dump(project_data, f, indent=4)

    # 6. Cleanup
    shutil.rmtree(temp_dir)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Decompilation successful! Output saved to: {output_dir.name}")
    print("Assets are now saved with human-readable names where possible, or MD5 hash names otherwise.")


def recompile() -> None:
    """
    Rebuilds the master project.json from all target script files and 
    zips everything back into a valid .sb3 file.
    """
    input_dir = Path(DECOMPILED_DIR_NAME)
    output_sb3 = Path(f"{PROJECT_NAME}.sb3")
    temp_repack_dir = Path("_temp_repack_assets")
    
    print(f"\n--- Recompiling to {output_sb3.name} ---")

    # 1. Validation and Preparation
    if not input_dir.is_dir():
        handle_error(f"Input directory '{input_dir.name}' is missing. Did you run decompile first?")
        
    if os.path.exists(output_sb3):
        create_backup(output_sb3)
    
    if temp_repack_dir.exists():
        shutil.rmtree(temp_repack_dir)
    temp_repack_dir.mkdir(exist_ok=True)

    # 2. Load Global Metadata
    global_metadata_path = input_dir / "global_project_metadata.json"
    if not global_metadata_path.is_file():
        handle_error("Could not find global_project_metadata.json. Cannot rebuild master JSON.")
        
    try:
        with open(global_metadata_path, 'r', encoding='utf-8') as f:
            master_project_data = json.load(f)
    except json.JSONDecodeError:
        handle_error("global_project_metadata.json is corrupted or invalid JSON.")

    # 3. Collect Targets and Assets
    master_project_data['targets'] = []
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Collecting scripts and assets...")
    
    for target_dir in input_dir.iterdir():
        # Skip directories that don't look like sprite folders
        if target_dir.is_dir() and target_dir.name not in [BACKUP_DIR_NAME, "_temp_repack_assets"]:
            script_path = target_dir / "scripts_and_properties.json"
            assets_path = target_dir / "Assets"
            
            if script_path.is_file():
                # a) Load Script/Target JSON
                try:
                    with open(script_path, 'r', encoding='utf-8') as f:
                        target_data = json.load(f)
                except json.JSONDecodeError:
                    print(f"[Warning] Skipping '{target_dir.name}' - script JSON is invalid.")
                    continue
                
                # b) Re-hash and Rename Assets (Update JSON pointers)
                for asset_type in ['costumes', 'sounds']:
                    for asset in target_data.get(asset_type, []):
                        current_filename = asset.get('md5ext') 
                        
                        if current_filename:
                            source_path = assets_path / current_filename
                            
                            if source_path.is_file():
                                # Calculate the MD5 hash of the current file content
                                md5_hash = calculate_md5(source_path)
                                asset_ext = Path(current_filename).suffix
                                new_md5ext = f"{md5_hash}{asset_ext}"
                                
                                # Update the target JSON to use the new official Scratch MD5 hash
                                asset['md5ext'] = new_md5ext
                                asset.pop('md5ext_placeholder', None) 
                                
                                # Copy asset to the flat temp directory using the required HASHED name
                                dest_path = temp_repack_dir / new_md5ext
                                # Check if the asset has already been copied (shared asset)
                                if not dest_path.is_file():
                                    shutil.copy(source_path, dest_path)
                            else:
                                # This warning should only happen now if a human deleted the file.
                                print(f"[{target_dir.name}] Warning: Asset file '{current_filename}' not found. Skipping.")
                
                # c) Append the fully reconstructed target JSON to the master list
                master_project_data['targets'].append(target_data)
            else:
                print(f"[Warning] Skipping directory '{target_dir.name}' - missing scripts_and_properties.json.")

    # 4. Write Rebuilt project.json
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Writing master project.json...")
    rebuilt_json_path = temp_repack_dir / "project.json"
    with open(rebuilt_json_path, 'w', encoding='utf-8') as f:
        # Scratch requires a compact JSON format, not indented, to save space.
        json.dump(master_project_data, f, separators=(',', ':'))

    # 5. Zip the Recompiled project
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Zipping contents to {output_sb3.name}...")
    try:
        with ZipFile(output_sb3, 'w') as sb3_zip:
            # Write project.json first
            sb3_zip.write(rebuilt_json_path, 'project.json')
            
            # Write all assets (which are now hash-named in the temp directory)
            for asset in temp_repack_dir.iterdir():
                if asset.name != "project.json":
                    # Write the file, keeping its name as the hashed filename
                    sb3_zip.write(asset, asset.name)
    except Exception as e:
        shutil.rmtree(temp_repack_dir)
        handle_error(f"Failed to zip {output_sb3.name}. Error: {e}")

    # 6. Cleanup
    shutil.rmtree(temp_repack_dir)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Success! {output_sb3.name} is ready.")
    print("NOTE: Open the project to let TurboWarp handle its compression!.")


def main() -> None:
    """Main function to handle command-line arguments."""
    if len(sys.argv) < 2:
        print("Usage: python sb3_toolchain.py <command>")
        print("Commands:")
        print("  decompile  - Unzips and restructures the .sb3 for human readability.")
        print("  recompile  - Rebuilds the .sb3 from the decompiled folders.")
        sys.exit(0)
    
    command = sys.argv[1].lower()
    
    if command == 'decompile':
        decompile()
    elif command == 'recompile':
        recompile()
    else:
        print(f"Unknown command: {command}")
        print("Use 'decompile' or 'recompile'.")


if __name__ == "__main__":
    main()
